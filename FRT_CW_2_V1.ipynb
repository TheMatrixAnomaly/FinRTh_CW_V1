{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e3d1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case       w1     w2     w3   VaR_SGLD    CVaR_SGLD    w1*    w2*    w3*       VaR*      CVaR*\n",
      "-----------------------------------------------------------------------------------------------\n",
      "1       0.332  0.341  0.327      0.935        1.165  0.333  0.343  0.323      0.942      1.165\n",
      "2       0.325  0.358  0.317      0.962        1.211  0.333  0.343  0.323      0.956      1.210\n",
      "3       0.333  0.356  0.310      0.942        1.201  0.323  0.354  0.323      0.953      1.201\n",
      "4       0.333  0.342  0.324      0.934        1.172  0.333  0.343  0.323      0.938      1.172\n",
      "5       0.327  0.323  0.351      0.925        1.166  0.333  0.323  0.343      0.934      1.166\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Parameters\n",
    "gamma = 1e-8\n",
    "beta = 1e8\n",
    "lambda_init = 1e-4\n",
    "n_iterations = 10**6\n",
    "burn_in_samples = 10000\n",
    "q_bar = 0.95\n",
    "n_samples = 10000\n",
    "\n",
    "def compute_softmax(w):\n",
    "    return F.softmax(w - torch.max(w), dim=0)\n",
    "\n",
    "def generate_samples(dist_params, n_samples):\n",
    "    return torch.stack([\n",
    "        torch.normal(mean=mu, std=sigma, size=(n_samples,)).to(device)\n",
    "        for mu, sigma in dist_params\n",
    "    ])\n",
    "\n",
    "# --- SGLD CVaR Minimization (with standardization) ---\n",
    "def sgld_cvar(x_samples):\n",
    "    # Standardize\n",
    "    means = torch.mean(x_samples, dim=1, keepdim=True)\n",
    "    stds = torch.std(x_samples, dim=1, keepdim=True) + 1e-8\n",
    "    x_std = (x_samples - means) / stds\n",
    "\n",
    "    # Initialize theta from quantile\n",
    "    initial_losses = -torch.sum(x_std, dim=0)\n",
    "    theta = torch.tensor(torch.quantile(initial_losses, q_bar).item(), device=device, requires_grad=True)\n",
    "    weights = torch.randn(3, device=device, requires_grad=True)\n",
    "\n",
    "    optimizer = torch.optim.SGD([theta, weights], lr=lambda_init)\n",
    "    theta_values = []\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        idx = torch.randint(0, n_samples, (1,))\n",
    "        x_sample = x_std[:, idx].squeeze(1)\n",
    "        softmax_weights = compute_softmax(weights)\n",
    "        portfolio_loss = -torch.sum(softmax_weights * x_sample)\n",
    "\n",
    "        loss = theta + (1 / (1 - q_bar)) * F.relu(portfolio_loss - theta) \\\n",
    "               + gamma * torch.sum(weights**2) + gamma * theta**2\n",
    "\n",
    "        noise_theta = torch.randn(1, device=device) * torch.sqrt(torch.tensor(2 * lambda_init / beta))\n",
    "        noise_weights = torch.randn(3, device=device) * torch.sqrt(torch.tensor(2 * lambda_init / beta))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            theta -= lambda_init * theta.grad + noise_theta.item()\n",
    "            weights -= lambda_init * weights.grad + noise_weights\n",
    "            theta.grad.zero_()\n",
    "            weights.grad.zero_()\n",
    "\n",
    "        if i >= n_iterations - burn_in_samples:\n",
    "            theta_values.append(theta.item())\n",
    "\n",
    "    final_weights = compute_softmax(weights).detach().cpu().numpy()\n",
    "    losses = [-torch.sum(compute_softmax(weights).detach() * x_std[:, i]).item() for i in range(n_samples)]\n",
    "    var = torch.mean(torch.tensor(theta_values)).item()\n",
    "    cvar = var + torch.mean(F.relu(torch.tensor(losses) - var)) / (1 - q_bar)\n",
    "    return var, cvar.item(), final_weights  # negative sign = back to return space\n",
    "\n",
    "# --- Grid Search Reference (also standardized) ---\n",
    "def grid_search_ref(x_samples):\n",
    "    means = torch.mean(x_samples, dim=1, keepdim=True)\n",
    "    stds = torch.std(x_samples, dim=1, keepdim=True) + 1e-8\n",
    "    x_std = (x_samples - means) / stds\n",
    "\n",
    "    grid = torch.linspace(0, 1, 100)\n",
    "    best_cvar = float(\"inf\")\n",
    "    best_var = None\n",
    "    best_weights = None\n",
    "\n",
    "    for w1 in grid:\n",
    "        for w2 in grid:\n",
    "            if w1 + w2 > 1:\n",
    "                continue\n",
    "            w3 = 1 - w1 - w2\n",
    "            weights = torch.tensor([w1, w2, w3], device=device)\n",
    "            losses = -torch.sum(weights.unsqueeze(1) * x_std, dim=0)\n",
    "            var = torch.quantile(losses, q_bar).item()\n",
    "            cvar = var + torch.mean(F.relu(losses - var)) / (1 - q_bar)\n",
    "            if cvar < best_cvar:\n",
    "                best_cvar = cvar.item()\n",
    "                best_var = var\n",
    "                best_weights = weights.cpu().numpy()\n",
    "\n",
    "    return best_var, best_cvar, best_weights\n",
    "\n",
    "# --- Run All Test Cases ---\n",
    "def main():\n",
    "    torch.manual_seed(42)\n",
    "    cases = [\n",
    "        [(500, 1), (0, 1e6), (0, 1e-4)],\n",
    "        [(500, 1), (0, 1e6), (0, 1)],\n",
    "        [(0, 1e3), (0, 1), (0, 4)],\n",
    "        [(0, 1), (1, 4), (0, 1e-4)],\n",
    "        [(0, 1), (1, 4), (2, 1)]\n",
    "    ]\n",
    "\n",
    "    print(f\"{'Case':<6} {'w1':>6} {'w2':>6} {'w3':>6} {'VaR_SGLD':>10} {'CVaR_SGLD':>12} {'w1*':>6} {'w2*':>6} {'w3*':>6} {'VaR*':>10} {'CVaR*':>10}\")\n",
    "    print(\"-\" * 95)\n",
    "\n",
    "    for idx, dist_params in enumerate(cases):\n",
    "        x_samples = generate_samples(dist_params, n_samples)\n",
    "        var_sgld, cvar_sgld, weights_sgld = sgld_cvar(x_samples)\n",
    "        var_ref, cvar_ref, weights_ref = grid_search_ref(x_samples)\n",
    "\n",
    "        print(f\"{idx+1:<6} \"\n",
    "              f\"{weights_sgld[0]:6.3f} {weights_sgld[1]:6.3f} {weights_sgld[2]:6.3f} \"\n",
    "              f\"{var_sgld:10.3f} {cvar_sgld:12.3f} \"\n",
    "              f\"{weights_ref[0]:6.3f} {weights_ref[1]:6.3f} {weights_ref[2]:6.3f} \"\n",
    "              f\"{var_ref:10.3f} {cvar_ref:10.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237d95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
